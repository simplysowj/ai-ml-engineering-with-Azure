{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NaNc_B-6xjXS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Practice activity: Implementing deep learning techniques\n",
        "Introduction\n",
        "In this lab, you will implement three different deep learning techniques: feedforward neural networks (FNNs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs).\n",
        "\n",
        "By the end of this activity, you will:\n",
        "\n",
        "Implement and train models using FNN, CNN, and RNN architectures.\n",
        "\n",
        "Compare the performance of each architecture on different types of data.\n",
        "\n",
        "Gain hands-on experience using TensorFlow’s Keras API.\n",
        "\n",
        "Step-by-step instructions:\n",
        "Step 1: Set up the environment\n",
        "Before starting, ensure you have TensorFlow installed. You can install it using the following command:\n",
        "\n",
        "1\n",
        "pip install tensorflow\n",
        "\n",
        "After installation, import the necessary libraries to build and train the neural networks:\n",
        "\n",
        "21\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "Step 2: Implement a feedforward neural network (FNN)\n",
        "Objective\n",
        "Implement a simple FNN to perform classification on the Iris dataset.\n",
        "\n",
        "Steps\n",
        "1. Load the Iris dataset\n",
        "123456789101112131415\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode labels\n",
        "\n",
        "\n",
        "2. Define the FNN architecture\n",
        "123456\n",
        "# Build the FNN model\n",
        "model_fnn = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # 3 output classes for the Iris dataset\n",
        "])\n",
        "\n",
        "3. Compile and train the model\n",
        "12345\n",
        "# Compile the model\n",
        "model_fnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_fnn.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "Step 3: Implement a convolutional neural network (CNN)\n",
        "Objective\n",
        "Implement a CNN to classify images from the CIFAR-10 dataset.\n",
        "\n",
        "Steps\n",
        "1. Load the CIFAR-10 dataset\n",
        "12345\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "2. Define the CNN architecture\n",
        "12345678910\n",
        "# Build the CNN model\n",
        "model_cnn = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # 10 output classes for CIFAR-10\n",
        "])\n",
        "\n",
        "3. Compile and train the model\n",
        "12345\n",
        "# Compile the model\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_cnn.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))\n",
        "\n",
        "Step 4: Implement a recurrent neural network (RNN)\n",
        "Objective\n",
        "Implement an RNN for time-series prediction using synthetic sequential data.\n",
        "\n",
        "Steps\n",
        "1. Create synthetic sequential data for a sine wave\n",
        "12345678910111213141516171819\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic sine wave data\n",
        "t = np.linspace(0, 100, 10000)\n",
        "X = np.sin(t).reshape(-1, 1)\n",
        "\n",
        "# Prepare sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "\n",
        "\n",
        "2. Define the RNN architecture\n",
        "12345\n",
        "# Build the RNN model\n",
        "model_rnn = models.Sequential([\n",
        "    layers.SimpleRNN(128, input_shape=(seq_length, 1)),\n",
        "    layers.Dense(1)  # Output is a single value (next point in the sequence)\n",
        "])\n",
        "\n",
        "3. Compile and train the model\n",
        "12345\n",
        "# Compile the model\n",
        "model_rnn.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model_rnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "Step 5: Compare performance\n",
        "After training the models, compare their performance based on the following:\n",
        "\n",
        "FNN: classification accuracy on the Iris dataset\n",
        "\n",
        "CNN: classification accuracy on the CIFAR-10 dataset\n",
        "\n",
        "RNN: mean squared error for predicting the next value in the sine wave sequence\n",
        "\n",
        "Conclusion\n",
        "In this lab, you implemented three distinct deep learning architectures—FNNs, CNNs, and RNNs—each tailored to specific types of data and tasks. By training and evaluating these models on the Iris dataset, CIFAR-10 images, and synthetic sine wave data, you observed the unique strengths and applications of each architecture. This hands-on experience will deepen your understanding of how different neural network designs can be applied effectively in various scenarios, preparing you for more advanced projects in the AI/ML domain. Remember to consider the nature of your data and the specific requirements of your task when choosing the appropriate architecture in your future work."
      ],
      "metadata": {
        "id": "EsjnRx9JxmQe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RXf-w6-bx4oE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PdefeJbNyghs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZyWm-0a0yg7M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M3iPO0XpyNmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this lab, you will implement three different deep learning techniques: feedforward neural networks (FNNs), convolutional neural networks (CNNs), and recurrent neural networks (RNNs).\n",
        "\n",
        "By the end of this activity, you will:\n",
        "\n",
        "Implement and train models using FNN, CNN, and RNN architectures.\n",
        "\n",
        "Compare the performance of each architecture on different types of data.\n",
        "\n",
        "Gain hands-on experience using TensorFlow’s Keras API.\n",
        "\n",
        "Step-by-step instructions:\n",
        "Step 1: Set up the environment\n",
        "Before starting, ensure you have TensorFlow installed. You can install it using the following command:"
      ],
      "metadata": {
        "id": "2m50Ir02y1Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efilw2tPy2Mo",
        "outputId": "38e6c93a-9e52-491c-ad41-6c308db760b2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After installation, import the necessary libraries to build and train the neural networks:\n",
        "\n"
      ],
      "metadata": {
        "id": "Ts9jmGnLy7wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "fJQ1r47ty8d5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Implement a feedforward neural network (FNN)\n",
        "Objective\n",
        "Implement a simple FNN to perform classification on the Iris dataset.\n",
        "\n",
        "Steps\n",
        "1. Load the Iris dataset"
      ],
      "metadata": {
        "id": "vbOtFoirzAdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encode labels\n",
        "# The 'sparse' argument is no longer supported,\n",
        "# it defaults to returning a sparse array and 'sparse=False' has been removed.\n",
        "# To get a dense array, use toarray() on the output.\n",
        "encoder = OneHotEncoder()\n",
        "y = encoder.fit_transform(y).toarray()\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "sdoOMgsQzEP2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n_d-rYM8zIwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the FNN architecture"
      ],
      "metadata": {
        "id": "fdkr4RqCzMAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the FNN model\n",
        "model_fnn = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # 3 output classes for the Iris dataset\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dp9v_ivzMmZ",
        "outputId": "05a64b1c-e4b3-4c01-fbb0-87f5e5919ec5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compile and train the model"
      ],
      "metadata": {
        "id": "mx8ThVtCzUrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_fnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_fnn.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NstwZ3VTzW_V",
        "outputId": "b83bf1b0-2e9a-4f3c-cc2f-ca828964e890"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.3417 - loss: 1.4156 - val_accuracy: 0.3333 - val_loss: 1.2123\n",
            "Epoch 2/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4029 - loss: 1.1580 - val_accuracy: 0.4333 - val_loss: 1.0603\n",
            "Epoch 3/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4100 - loss: 1.0110 - val_accuracy: 0.3333 - val_loss: 0.9789\n",
            "Epoch 4/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4098 - loss: 0.9388 - val_accuracy: 0.4000 - val_loss: 0.9170\n",
            "Epoch 5/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5767 - loss: 0.8939 - val_accuracy: 0.7000 - val_loss: 0.8492\n",
            "Epoch 6/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6165 - loss: 0.8493 - val_accuracy: 0.7000 - val_loss: 0.7922\n",
            "Epoch 7/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6727 - loss: 0.7877 - val_accuracy: 0.7000 - val_loss: 0.7473\n",
            "Epoch 8/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6612 - loss: 0.7462 - val_accuracy: 0.7333 - val_loss: 0.7128\n",
            "Epoch 9/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6700 - loss: 0.7142 - val_accuracy: 0.7333 - val_loss: 0.6772\n",
            "Epoch 10/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7140 - loss: 0.6665 - val_accuracy: 0.7667 - val_loss: 0.6421\n",
            "Epoch 11/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7452 - loss: 0.6589 - val_accuracy: 0.7667 - val_loss: 0.6158\n",
            "Epoch 12/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8931 - loss: 0.6208 - val_accuracy: 0.8000 - val_loss: 0.5871\n",
            "Epoch 13/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7733 - loss: 0.5794 - val_accuracy: 0.7333 - val_loss: 0.5615\n",
            "Epoch 14/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7277 - loss: 0.5517 - val_accuracy: 0.7333 - val_loss: 0.5423\n",
            "Epoch 15/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7365 - loss: 0.5439 - val_accuracy: 0.8000 - val_loss: 0.5274\n",
            "Epoch 16/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8648 - loss: 0.5165 - val_accuracy: 0.8667 - val_loss: 0.5141\n",
            "Epoch 17/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9117 - loss: 0.5345 - val_accuracy: 0.8333 - val_loss: 0.5079\n",
            "Epoch 18/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9623 - loss: 0.4895 - val_accuracy: 0.8667 - val_loss: 0.4901\n",
            "Epoch 19/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9590 - loss: 0.4740 - val_accuracy: 0.8667 - val_loss: 0.4765\n",
            "Epoch 20/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9065 - loss: 0.4782 - val_accuracy: 0.8667 - val_loss: 0.4650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dba66f2e0b0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected outcome\n",
        "After training, the FNN should achieve accuracy levels above 90 percent on the Iris dataset, as the problem is relatively simple.\n",
        "\n",
        "You can evaluate the model using:"
      ],
      "metadata": {
        "id": "I3IM7FV02O5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_fnn.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxx8lF852PtQ",
        "outputId": "7e7d2c49-b8b2-4d0f-ae2c-3352d866bb42"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8667 - loss: 0.4650\n",
            "Test Accuracy: 0.8666666746139526\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LaspxNZ8zZ68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Implement a convolutional neural network (CNN)\n",
        "Objective\n",
        "Implement a CNN to classify images from the CIFAR-10 dataset.\n",
        "\n",
        "Steps\n",
        "1. Load the CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "8er1SClDzcg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize pixel values to be between 0 and 1\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "05SyjwgHzdl-"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the CNN architecture"
      ],
      "metadata": {
        "id": "ud9Y-rY9zhBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the CNN model\n",
        "model_cnn = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')  # 10 output classes for CIFAR-10\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n1vJ3RKzjir",
        "outputId": "8c6c726e-ec8b-46ed-d52a-bf23a0dfdc1b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compile and train the model"
      ],
      "metadata": {
        "id": "uLgFmE0MzmWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_cnn.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVm2V8c4zpA5",
        "outputId": "811524c1-1569-468e-c8dc-c8b20e759613"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 89ms/step - accuracy: 0.3791 - loss: 1.7127 - val_accuracy: 0.5432 - val_loss: 1.2909\n",
            "Epoch 2/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 86ms/step - accuracy: 0.5872 - loss: 1.1742 - val_accuracy: 0.6131 - val_loss: 1.1033\n",
            "Epoch 3/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 86ms/step - accuracy: 0.6453 - loss: 1.0193 - val_accuracy: 0.6262 - val_loss: 1.0734\n",
            "Epoch 4/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 83ms/step - accuracy: 0.6778 - loss: 0.9330 - val_accuracy: 0.6444 - val_loss: 1.0317\n",
            "Epoch 5/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 82ms/step - accuracy: 0.7004 - loss: 0.8691 - val_accuracy: 0.6764 - val_loss: 0.9519\n",
            "Epoch 6/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 83ms/step - accuracy: 0.7245 - loss: 0.7966 - val_accuracy: 0.6926 - val_loss: 0.8955\n",
            "Epoch 7/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 82ms/step - accuracy: 0.7428 - loss: 0.7450 - val_accuracy: 0.6895 - val_loss: 0.9109\n",
            "Epoch 8/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 88ms/step - accuracy: 0.7611 - loss: 0.6899 - val_accuracy: 0.6876 - val_loss: 0.9359\n",
            "Epoch 9/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 81ms/step - accuracy: 0.7742 - loss: 0.6581 - val_accuracy: 0.7023 - val_loss: 0.8758\n",
            "Epoch 10/10\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 82ms/step - accuracy: 0.7926 - loss: 0.6049 - val_accuracy: 0.7043 - val_loss: 0.8835\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dba669997e0>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected outcome\n",
        "After training, the CNN should achieve accuracy between 70–80 percent on the test data, as CIFAR-10 is a more challenging dataset.\n",
        "\n",
        "Evaluate the model using:"
      ],
      "metadata": {
        "id": "wa8GsRaM2EEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_cnn.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFAvmkJq2EwP",
        "outputId": "5fc1a46d-d2e3-492d-b251-786a76c60b96"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7110 - loss: 0.8699\n",
            "Test Accuracy: 0.7042999863624573\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Implement a recurrent neural network (RNN)\n",
        "Objective\n",
        "Implement an RNN for time-series prediction using synthetic sequential data.\n",
        "\n",
        "Steps\n",
        "1. Create synthetic sequential data for a sine wave"
      ],
      "metadata": {
        "id": "hINMerxHztA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate synthetic sine wave data\n",
        "t = np.linspace(0, 100, 10000)\n",
        "X = np.sin(t).reshape(-1, 1)\n",
        "\n",
        "# Prepare sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i+seq_length])\n",
        "        y_seq.append(data[i+seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_length = 100\n",
        "X_seq, y_seq = create_sequences(X, seq_length)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qTkd5LQtzw1m"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define the RNN architecture"
      ],
      "metadata": {
        "id": "XMYFxTUyz2S-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model\n",
        "model_rnn = models.Sequential([\n",
        "    layers.SimpleRNN(128, input_shape=(seq_length, 1)),\n",
        "    layers.Dense(1)  # Output is a single value (next point in the sequence)\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmFN3Gi7z3U-",
        "outputId": "f36ffb55-f4e4-4b02-e5c7-bb30bde7f929"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Compile and train the model"
      ],
      "metadata": {
        "id": "Vg-dsKahz6G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model_rnn.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "model_rnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm6Lx2JLz8_O",
        "outputId": "bd8cea9c-ff40-4342-d5c7-1d93e481ac33"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 0.0481 - val_loss: 6.3119e-06\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 4.6192e-06 - val_loss: 2.3821e-06\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 2.9443e-06 - val_loss: 4.7059e-06\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 30ms/step - loss: 9.0757e-06 - val_loss: 9.1589e-07\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - loss: 1.3191e-06 - val_loss: 4.4590e-06\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 5.5550e-06 - val_loss: 6.9771e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 5.2028e-06 - val_loss: 8.0306e-07\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 2.9430e-05 - val_loss: 1.4129e-06\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 1.0082e-06 - val_loss: 1.1186e-06\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 1.0596e-06 - val_loss: 1.0883e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dba61bc63b0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Compare performance\n",
        "After training the models, compare their performance based on the following:\n",
        "\n",
        "FNN: classification accuracy on the Iris dataset\n",
        "\n",
        "CNN: classification accuracy on the CIFAR-10 dataset\n",
        "\n",
        "RNN: mean squared error for predicting the next value in the sine wave sequence\n",
        "\n",
        "Conclusion\n",
        "In this lab, you implemented three distinct deep learning architectures—FNNs, CNNs, and RNNs—each tailored to specific types of data and tasks. By training and evaluating these models on the Iris dataset, CIFAR-10 images, and synthetic sine wave data, you observed the unique strengths and applications of each architecture. This hands-on experience will deepen your understanding of how different neural network designs can be applied effectively in various scenarios, preparing you for more advanced projects in the AI/ML domain. Remember to consider the nature of your data and the specific requirements of your task when choosing the appropriate architecture in your future work.\n",
        "\n"
      ],
      "metadata": {
        "id": "oU-hzb9v0ADy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of results\n",
        "After completing the activity:\n",
        "\n",
        "FNN: you should have achieved more than 90 percent accuracy on the Iris dataset, showcasing that FNNs are well-suited for simple classification tasks.\n",
        "\n",
        "CNN: the CNN should have achieved around 70–80 percent accuracy on the CIFAR-10 dataset, highlighting the CNN’s ability to recognize spatial features in image data.\n",
        "\n",
        "RNN: the RNN should have minimized MSE for predicting the sine wave, demonstrating the RNN's capacity for handling sequential data.\n",
        "\n",
        "Each architecture has strengths for specific tasks, and understanding how to implement and optimize them is crucial for solving different types of problems.\n",
        "\n",
        "Conclusion\n",
        "In this activity and walkthrough, you have gained practical experience in implementing and training three distinct neural network architectures. You learned how each model operates and its applicability to various types of data, preparing you to choose the appropriate architecture for your own machine learning projects. By understanding these foundational techniques in AI/ML engineering, you are now equipped to tackle more complex challenges in the field.\n",
        "\n"
      ],
      "metadata": {
        "id": "nrarfWr80w_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing a recurrent neural network\n",
        "Objective\n",
        "We built an RNN to predict the next value in a sine wave sequence, a classic example of time-series prediction.\n",
        "\n",
        "Solution walkthrough\n",
        "Step 1: Create the data\n",
        "A synthetic sine wave dataset was created and split into sequences for training and testing."
      ],
      "metadata": {
        "id": "8EsfRlW61EXe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate synthetic sine wave data\n",
        "t = np.linspace(0, 100, 10000)\n",
        "X = np.sin(t).reshape(-1, 1)\n",
        "\n",
        "# Prepare sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X_seq, y_seq = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X_seq.append(data[i:i+seq_length])\n",
        "        y_seq.append(data[i+seq_length])\n",
        "    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "seq_length = 100\n",
        "X_seq, y_seq = create_sequences(X, seq_length)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QA7nuB-o1F7w"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Build the RNN\n",
        "A simple RNN architecture was implemented with one recurrent layer and a single output neuron for predicting the next value in the sequence."
      ],
      "metadata": {
        "id": "MrCwryZn1L_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model\n",
        "model_rnn = models.Sequential([\n",
        "    layers.SimpleRNN(128, input_shape=(seq_length, 1)),\n",
        "    layers.Dense(1)  # Single output for next value prediction\n",
        "])"
      ],
      "metadata": {
        "id": "oI1xIMuV1PUI"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Compile and train the model\n",
        "The model was compiled using the mean squared error (MSE) loss function and trained for ten epochs.\n",
        "\n"
      ],
      "metadata": {
        "id": "-xLK65zq1SGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and train the model\n",
        "model_rnn.compile(optimizer='adam', loss='mse')\n",
        "model_rnn.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVhZ1y1S1VcC",
        "outputId": "cf1d8366-ac41-4b03-f77f-1ef76ad0d155"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - loss: 0.0069 - val_loss: 3.3763e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 29ms/step - loss: 2.2415e-05 - val_loss: 1.6736e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 1.5788e-05 - val_loss: 5.0780e-06\n",
            "Epoch 4/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 29ms/step - loss: 6.1322e-06 - val_loss: 1.5333e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - loss: 8.4750e-06 - val_loss: 4.1695e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - loss: 9.4345e-06 - val_loss: 3.7512e-06\n",
            "Epoch 7/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 1.4927e-06 - val_loss: 6.1705e-06\n",
            "Epoch 8/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 5.1092e-06 - val_loss: 1.4860e-05\n",
            "Epoch 9/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 30ms/step - loss: 4.6034e-05 - val_loss: 3.7367e-07\n",
            "Epoch 10/10\n",
            "\u001b[1m248/248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 5.6466e-07 - val_loss: 6.9153e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dba61a8a3b0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y1mOztya0x2o"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Expected outcome\n",
        "The RNN should be able to predict the sine wave sequence with low MSE after training.\n",
        "\n",
        "You can evaluate the model using:"
      ],
      "metadata": {
        "id": "5cSe6k2j1jYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse = model_rnn.evaluate(X_test, y_test)\n",
        "print(f'Test MSE: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XksZ1XVJ1kK2",
        "outputId": "443d880e-c236-42c7-eb2f-6034f0d00838"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.9919e-06\n",
            "Test MSE: 6.915267476870213e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary of results\n",
        "After completing the activity:\n",
        "\n",
        "FNN: you should have achieved more than 90 percent accuracy on the Iris dataset, showcasing that FNNs are well-suited for simple classification tasks.\n",
        "\n",
        "CNN: the CNN should have achieved around 70–80 percent accuracy on the CIFAR-10 dataset, highlighting the CNN’s ability to recognize spatial features in image data.\n",
        "\n",
        "RNN: the RNN should have minimized MSE for predicting the sine wave, demonstrating the RNN's capacity for handling sequential data.\n",
        "\n",
        "Each architecture has strengths for specific tasks, and understanding how to implement and optimize them is crucial for solving different types of problems.\n",
        "\n",
        "Conclusion\n",
        "In this activity and walkthrough, you have gained practical experience in implementing and training three distinct neural network architectures. You learned how each model operates and its applicability to various types of data, preparing you to choose the appropriate architecture for your own machine learning projects. By understanding these foundational techniques in AI/ML engineering, you are now equipped to tackle more complex challenges in the field."
      ],
      "metadata": {
        "id": "TRgNjhbx1qV_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Qq02hM41rJf"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}