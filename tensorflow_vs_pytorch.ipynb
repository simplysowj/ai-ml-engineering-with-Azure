{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2srMMrBAOVt",
        "outputId": "cd7f0866-af08-414b-83c8-23645275c143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow\n",
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6HP_Jb7UAf2h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogsvp3pKAgk6"
      },
      "source": [
        "For this activity, you will use the CIFAR-10 dataset, which consists of 60,000 32 × 32 color images across 10 different classes. You will implement the same neural network architecture using both TensorFlow and PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5JuOQExJAYmO"
      },
      "outputs": [],
      "source": [
        "\n",
        "#load the dataset with tensorflow(keras)\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(train_images, train_activityels), (test_images, test_activityels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Normalize the images to a range of 0 to 1\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tngO62BEAw_2",
        "outputId": "cb265d81-9e56-4cd7-df28-1320256d9745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#loading with pytorch\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define a transformation to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Gsxq8YbhA3uB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation\n",
        "In both TensorFlow and PyTorch, the images are normalized so that pixel values range from 0 to 1 in TensorFlow and from –1 to 1 in PyTorch (using transforms.Normalize).\n",
        "\n",
        "In PyTorch, we define a DataLoader to handle the batching and shuffling of the dataset."
      ],
      "metadata": {
        "id": "ZvonQF7NIC7u"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3xz5nLLjIDrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6sEBkCbBHvu"
      },
      "source": [
        "Step 3: Define the neural network architecture\n",
        "For both frameworks, we will define the same neural network architecture: a simple convolutional neural network (CNN) consisting of two convolutional layers followed by two fully connected layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAl2KPT3BIqT",
        "outputId": "19d2633e-b260-4546-c3c0-30e91faf58f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "#Define the CNN in TensorFlow (Keras)\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D0cPTxsDBQHT"
      },
      "outputs": [],
      "source": [
        "#Define the CNN in PyTorch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
        "        self.fc1 = nn.Linear(64 * 6 * 6, 64)\n",
        "        self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 64 * 6 * 6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fkold5_BgBl"
      },
      "source": [
        "Both architectures consist of two convolutional layers followed by pooling, flattening, and fully connected layers.\n",
        "\n",
        "In TensorFlow, the input shape is explicitly defined, whereas PyTorch calculates the shape dynamically during the forward pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nEBR2JI7Bg5R"
      },
      "outputs": [],
      "source": [
        "# Compile the model in tensorflow\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "a60gxDyLBnHw"
      },
      "outputs": [],
      "source": [
        "#define the optimizer in pytorch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Create an instance of the SimpleCNN model\n",
        "pytorch_model = SimpleCNN()\n",
        "\n",
        "# Define the optimizer and loss function using the PyTorch model instance\n",
        "optimizer = optim.Adam(pytorch_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "y2Eh0t5CB03K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Icgn6ZNB4Td"
      },
      "source": [
        "Step 5: Training the neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzPhf2U4B5KH",
        "outputId": "dea3b474-eab5-4c3c-82b6-137066c60626"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 46ms/step - accuracy: 0.3695 - loss: 1.7333 - val_accuracy: 0.5510 - val_loss: 1.2789\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 46ms/step - accuracy: 0.5757 - loss: 1.1999 - val_accuracy: 0.6120 - val_loss: 1.1157\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 45ms/step - accuracy: 0.6387 - loss: 1.0320 - val_accuracy: 0.6576 - val_loss: 0.9912\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 45ms/step - accuracy: 0.6694 - loss: 0.9412 - val_accuracy: 0.6494 - val_loss: 1.0003\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 46ms/step - accuracy: 0.6989 - loss: 0.8724 - val_accuracy: 0.6836 - val_loss: 0.9350\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 45ms/step - accuracy: 0.7144 - loss: 0.8273 - val_accuracy: 0.6789 - val_loss: 0.9370\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 45ms/step - accuracy: 0.7303 - loss: 0.7751 - val_accuracy: 0.6879 - val_loss: 0.9117\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 45ms/step - accuracy: 0.7421 - loss: 0.7446 - val_accuracy: 0.6857 - val_loss: 0.9327\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 47ms/step - accuracy: 0.7555 - loss: 0.6940 - val_accuracy: 0.6955 - val_loss: 0.9110\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 45ms/step - accuracy: 0.7678 - loss: 0.6655 - val_accuracy: 0.6884 - val_loss: 0.9474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a3e11728100>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Train the model for 10 epochs in tensorflow\n",
        "model.fit(train_images, train_activityels, epochs=10, batch_size=32, validation_data=(test_images, test_activityels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjnlD2e5B-7e",
        "outputId": "f9667dcd-c07d-4695-9a99-8fb4afc01a65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.4010555775823001\n",
            "Epoch 1, Loss: 1.4010555775823001\n",
            "Epoch 2, Loss: 1.033403793436857\n",
            "Epoch 2, Loss: 1.033403793436857\n",
            "Epoch 3, Loss: 0.8939307762580427\n",
            "Epoch 3, Loss: 0.8939307762580427\n",
            "Epoch 4, Loss: 0.8112368592259522\n",
            "Epoch 4, Loss: 0.8112368592259522\n",
            "Epoch 5, Loss: 0.7418212437011916\n",
            "Epoch 5, Loss: 0.7418212437011916\n",
            "Epoch 6, Loss: 0.6829046588903501\n",
            "Epoch 6, Loss: 0.6829046588903501\n",
            "Epoch 7, Loss: 0.637353381312435\n",
            "Epoch 7, Loss: 0.637353381312435\n",
            "Epoch 8, Loss: 0.5932897175265975\n",
            "Epoch 8, Loss: 0.5932897175265975\n",
            "Epoch 9, Loss: 0.5581374208342167\n",
            "Epoch 9, Loss: 0.5581374208342167\n",
            "Epoch 10, Loss: 0.520843729901146\n",
            "Epoch 10, Loss: 0.520843729901146\n"
          ]
        }
      ],
      "source": [
        "# Training loop for PyTorch\n",
        "# Training loop for PyTorch\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for inputs, activityels in trainloader:\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        outputs = pytorch_model(inputs)  # Forward pass using the PyTorch model\n",
        "        loss = criterion(outputs, activityels)  # Calculate loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Optimize\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')\n",
        "\n",
        "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(trainloader)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_a-NdznCGr0"
      },
      "source": [
        "Explanation\n",
        "TensorFlow simplifies the training process using the .fit() method, while PyTorch requires manual loops to handle the forward pass, backpropagation, and optimization steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eg9j8OhJCHUI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzFLWP7dCKtg"
      },
      "source": [
        "Step 6: Evaluate the model\n",
        "Evaluate the model in TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "AbKkOmfbCLVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79057878-9d1c-4f78-c4fb-6ceb192d8d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6890 - loss: 0.9405\n",
            "Test accuracy: 0.6883999705314636\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model in tensorflow\n",
        "test_loss, test_acc = model.evaluate(test_images, test_activityels)\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "MZ6xcU7sCTRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0433b1a-2f75-4dbd-aa89-082427e2132e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 71.16%\n"
          ]
        }
      ],
      "source": [
        "#evaluate in pytorch\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, activityels in testloader:\n",
        "        # Use the PyTorch model for prediction\n",
        "        outputs = pytorch_model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += activityels.size(0)\n",
        "        correct += (predicted == activityels).sum().item()\n",
        "\n",
        "print(f'Test accuracy: {100 * correct / total}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gOQtrfrCaLf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTB8uR5pCdQn"
      },
      "source": [
        "Step 7: Compare and analyze\n",
        "After training both models, compare their performance:\n",
        "\n",
        "Accuracy: Compare the test accuracy of both models.\n",
        "\n",
        "Ease of use: Which framework was easier to implement? Did TensorFlow’s higher-level API make implementation smoother, or did PyTorch's flexibility offer better control?\n",
        "\n",
        "Debugging: Reflect on the debugging process. Did PyTorch’s dynamic graph provide better insight, or did TensorFlow’s simplified process make it easier?\n",
        "\n",
        "Deliverables\n",
        "At the end of this activity, you should have:\n",
        "\n",
        "Your complete code for implementing and training the neural networks in both TensorFlow and PyTorch.\n",
        "\n",
        "A comparison report discussing:\n",
        "\n",
        "The test accuracy of both models.\n",
        "\n",
        "The ease of implementation in both frameworks.\n",
        "\n",
        "Key differences, including which framework you preferred and why.\n",
        "\n",
        "Conclusion\n",
        "By completing this activity, you’ve gained practical experience with two of the most popular deep learning frameworks. You’ve also compared how they differ in terms of implementation, ease of use, and performance. This will help you make informed decisions about which framework to use for your projects in the future.\n",
        "\n",
        "Completed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxUlwCn_CeJo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}